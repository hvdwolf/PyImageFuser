<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN">

<html>
<head>
<link rel="STYLESHEET" type="text/css" href="styles.css">
<link rel="shortcut icon" href="logo.ico" >
</head>
<body topmargin="20" leftmargin="50">
<H1>Aligning your images</H1>
<H2>Why aligining them?</H2>
Even on a tripod you might have "micro" shake which you will see when pixel-peeping.<br>
If you do stacking of handheld burst-mode images to reduce noise, in case you are without a tripod and can't use a slow shutter speed in
combination with a low ISO on a tripod, you better get rid of the first few and last few images
as they contain the most shake due to camera button press/release.


<H2>Alignment methods</H2>
OpenCV offers one alignment option and multiple keypoint detector options. In PyImageFuser we can use a number of those methods being:
<ul>
<li><strong>AlignMTB</strong>: This algorithm converts images to median threshold bitmaps (1 for pixels brighter than median luminance and 0 otherwise) and than aligns the resulting bitmaps using bit operations. It is invariant to exposure, so exposure values and camera response are not necessary.</li>
<li><strong>ECC</strong>: Enhanced Correlation Coefficient (ECC) Maximization</li>
<li><strong>ORB</strong>: Oriented FAST and Rotated BRIEF.</li>
<li><strong>SIFT</strong>: Scale Invariant Feature Transform (Note: Since 2020 SIFT is patent-free.</li>
</ul>
Note that all these methods are <a href="https://itsfoss.com/what-is-foss/" target="_blank">FOSS</a>. SIFT and SURF are patented.

<p><strong>AlignMTB</strong> is an aligning method using Median Threshold Bitmaps (MTB). This means that the images are first converted to these bitmaps, then having 1 for pixels higher than
median luminance and 0 for pixels lower than median luminance.
<p><strong>ECC</strong> is not feature based. It is a motion model alignment algorithm for alignment.<br>
For more info about ECC see this <a href="https://learnopencv.com/image-alignment-ecc-in-opencv-c-python/" target="_blank">Image Alignment (ECC) in OpenCV</a>
<p><strong>ORB</strong> is a feature based keypoint detector based on FAST, with rotation enhancements (rotated BRIEF).<br>
For more info about ORB see this <a href="https://docs.opencv.org/3.4/d1/d89/tutorial_py_orb.html" target="_blank">OpenCV tutorial artcle</a>
    or this <a href="https://learnopencv.com/image-alignment-feature-based-using-opencv-c-python/" target="_blank">Feature Based Image Alignment using OpenCV</a>.
<p><strong>SIFT</strong> extracts keypoints and computes its descriptors</p>

<H2>Pros/Cons of the methods</H2>
<ul>
    <li>AlignMTB: (Very) fast. Used for aligning images for Exposure Fusion (only), but does not always properly align.</li>
    <li>ECC: Very slow but accurate. Can be used for stacking (noise reduction) and exposure fusion.</li>
    <li>ORB: (Very) fast and robust. Used for aligning in (focus) stacks and exposure fusion. Not so good in exposure fusion where you have huge differences
     in exposure (up to +5/+6 or -5/-6), or on low res images (but who does use these anyway?)</li>
    <li>SIFT: Very slow but a very good keypoint descriptor.</li>
</ul>




<H2>ECC geometric image transformation models:</H2>
<p><strong>First the simple explanation:</strong><br>
See below the graphical representation of the geometric transformation models for images.<br>
<center><img src="./GeometricTransformationModels720p.png" border="0"></center>
Now let's assume our image is a piece of paper lying on a table.<br>
<ul>
<li>In "Translation" we simply slide the piece of paper a little (2-Dimensional).</li>
<li>In "Euclidean" we also rotate the piece of paper a little (2-Dimensional).</li>
<li><i>Now assume our piece of paper is a little elastic.</i></li>
<li>In "Euclidean" we shift and rotate it a bit, and we also stretch it a bit on the opposite corners (2-Dimensional).</li>
<li>In "Homography" (also called perspective) we shift, rotate, stretch and lift it slightly and uneven of the table (3-Dimensional).</li>
</ul>
<p><strong>Now the "scientific" explanation:</strong><br>
<ul>
<li>Translation ( MOTION_TRANSLATION ) : The first image can be shifted ( translated ) by (x , y) to obtain the second image. There are only two parameters x and y that need to be estimated.</li>
<li>Euclidean ( MOTION_EUCLIDEAN ) : The first image is a rotated and shifted version of the second image. There are three parameters â€” x, y and angle . In the Euclidean transformation of a square, the size does not change, parallel lines remain parallel, and right angles remain unchanged after transformation.</li>
<li>Affine ( MOTION_AFFINE ) : An affine transform is a combination of rotation, translation ( shift ), scale, and shear. This transform has six parameters. When a square undergoes an Affine transformation, parallel lines remain parallel, but lines meeting at right angles no longer remain orthogonal.</li>
<li>Homography ( MOTION_HOMOGRAPHY ) : All the transforms described above are 2D transforms. They do not account for 3D effects. A homography transform on the other hand can account for some 3D effects ( but not all ). This transform has 8 parameters. A square when transformed using a Homography can change to any quadrilateral.</li>
</ul>


See for OpenCV geometric transformation in images <a href="https://docs.opencv.org/4.7.0/da/d6e/tutorial_py_geometric_transformations.html" target="_blank">this</a> short article.


</body>
</html>
